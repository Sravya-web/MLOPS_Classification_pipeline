# ML Classification System - MLOps Best Practices

A complete, production-ready machine learning classification system demonstrating modern MLOps practices from data versioning to deployment.

![Python](https://img.shields.io/badge/Python-3.11+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green)
![Docker](https://img.shields.io/badge/Docker-Containerized-blue)
![Tests](https://img.shields.io/badge/Tests-pytest-orange)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [API Documentation](#api-documentation)
- [Testing](#testing)
- [Deployment](#deployment)

## ğŸ¯ Overview

This project implements a complete ML classification system following **all MLOps best practices**:

### Key Components:
1. **Data Layer**: PostgreSQL with Neon (serverless)
2. **ML Pipeline**: Scikit-learn with hyperparameter tuning
3. **Experiment Tracking**: Weights & Biases (W&B)
4. **API**: FastAPI with Prometheus metrics
5. **Frontend**: Streamlit interactive UI
6. **Deployment**: Docker + Render
7. **Monitoring**: Prometheus + Grafana
8. **CI/CD**: GitHub Actions workflows

## âœ¨ Features

- âœ… PostgreSQL database integration
- âœ… Hyperparameter tuning (Grid/Random/Bayesian Search)
- âœ… Weights & Biases experiment tracking
- âœ… FastAPI with Pydantic validation
- âœ… Streamlit frontend
- âœ… Docker containerization
- âœ… Prometheus + Grafana monitoring
- âœ… 15+ comprehensive pytest tests
- âœ… Flake8 + Pylint code quality
- âœ… GitHub Actions CI/CD
- âœ… Render deployment support

## âš¡ Quick Start

### Without Docker
```bash
# Setup
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Train model
python scripts/train.py

# Terminal 1: API
uvicorn backend.main:app --reload --port 8000

# Terminal 2: Frontend
streamlit run frontend/app.py
```

### With Docker Compose
```bash
docker-compose -f docker/docker-compose.yml up -d
```

Access:
- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Frontend**: http://localhost:8501
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000

## ğŸ“ Project Structure

```
ml-classification-system/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ ml_pipeline.py          # ML training & inference
â”‚   â”œâ”€â”€ data_manager.py         # Database operations
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py                  # Streamlit application
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_all.py             # 15+ comprehensive tests
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train.py                # Training script
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.csv             # Training dataset
â”œâ”€â”€ model_artifacts/
â”‚   â”œâ”€â”€ model.joblib
â”‚   â””â”€â”€ preprocessor.joblib
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â”œâ”€â”€ Dockerfile.frontend
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ backend.yml             # Backend CI/CD
â”‚   â””â”€â”€ frontend.yml            # Frontend CI/CD
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ“š API Documentation

### Key Endpoints

**Health Check**
```bash
GET /health
```

**Single Prediction**
```bash
POST /predict
{
  "feature1": 1.2,
  "feature2": 3.4,
  "feature3": 5.6,
  "feature4": 2.1,
  "feature5": 1.5
}
```

**Batch Predictions**
```bash
POST /predict-batch
[
  {"feature1": 1.2, ...},
  {"feature1": 2.3, ...}
]
```

**Metrics**
```bash
GET /metrics  # Prometheus metrics
GET /info     # Model information
```

## ğŸ§ª Testing

```bash
# All tests
pytest tests/ -v --cov=backend

# With coverage report
pytest tests/ --cov=backend --cov-report=html

# Specific test
pytest tests/test_all.py::TestMLPipeline::test_prediction -v
```

**Test Coverage**: 15+ tests covering:
- Data loading and validation
- ML pipeline training and evaluation
- API endpoints and error handling
- Batch predictions
- Integration tests

## ğŸš€ Deployment

### Render Deployment
1. Push to GitHub
2. Create Render services for backend and frontend
3. Set environment variables
4. Deploy

### Docker Local
```bash
docker-compose -f docker/docker-compose.yml up --build
```

## ğŸ“Š Monitoring

### Prometheus
- Request counts per endpoint
- Prediction latency
- Model accuracy metrics
- System health

### Grafana
- Pre-built dashboards
- Custom metrics visualization
- Alerts configuration

## ğŸ¯ Business Value

This system enables:
- **Automated Classification**: ML-powered predictions
- **Real-time Inference**: Sub-100ms predictions
- **Scalability**: Handles batch and single requests
- **Transparency**: Full experiment tracking with W&B
- **Reliability**: Comprehensive testing and CI/CD
- **Monitoring**: Production-grade observability

## ğŸ“ W&B Integration

Experiment tracking automatically logs:
- Hyperparameters
- Performance metrics (Accuracy, F1, ROC-AUC, Precision, Recall)
- Model artifacts
- Cross-validation results
- Training curves

## ğŸ” Environment Setup

```bash
cp .env.example .env
# Edit .env with:
DATABASE_URL=postgresql://user:password@host/db
WANDB_API_KEY=your_api_key
MODEL_PATH=model_artifacts/model.joblib
API_URL=http://localhost:8000
```

## ğŸ“ˆ Code Quality

```bash
# Format
black backend frontend tests

# Lint
flake8 backend frontend tests

# Type checking
mypy backend/**/*.py
```

All code follows PEP8 standards with Flake8 and Pylint checks in CI/CD.

## ğŸ”— Resources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Scikit-learn Guide](https://scikit-learn.org/)
- [Streamlit Docs](https://docs.streamlit.io/)
- [Docker Reference](https://docs.docker.com/)
- [Weights & Biases](https://wandb.ai/)

## ğŸ“„ License

MIT License

---

**Built with â¤ï¸ for MLOps Excellence** | v1.0.0
